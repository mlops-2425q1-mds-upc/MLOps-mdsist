{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "Create a CNN and train it using the data preprocessed on previous notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-11 13:35:19.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Users\\Adria.Portatil-Adria\\Documents\\uni\\MDS\\MLOPS\\MLOps-mdsist\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load envionment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Load packages\n",
    "import os\n",
    "\n",
    "import codecarbon as cc\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "from mdsist.architectures import CNN\n",
    "from mdsist.dataset import MdsistDataset\n",
    "from mdsist.config import PROCESSED_DATA_DIR, RAW_DATA_DIR, MODELS_DIR\n",
    "from mdsist.trainer import Trainer\n",
    "\n",
    "import mdsist.util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "EXPERIMENT_ID = 'CNN_v2_testing_deleteME2'\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0001\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "util.seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = MdsistDataset(PROCESSED_DATA_DIR / 'train.parquet', transform=transform)\n",
    "val_dataset = MdsistDataset(PROCESSED_DATA_DIR / 'validation.parquet', transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=1568, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "device = util.get_available_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log model complexity (params and flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-11 13:35:20.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.util\u001b[0m:\u001b[36mlog_model_complexity\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mFLOPS: 1.29 MMac\u001b[0m\n",
      "\u001b[32m2024-10-11 13:35:20.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.util\u001b[0m:\u001b[36mlog_model_complexity\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mParameters: 206.92 k\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "util.log_model_complexity(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/11 13:35:20 INFO mlflow.tracking.fluent: Experiment with name 'CNN_v2_testing_deleteME2' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-11 13:35:22.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mStart training for 5 epochs...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:27<01:49, 27.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-11 13:35:50.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mEpoch [1/5]\u001b[0m\n",
      "\u001b[32m2024-10-11 13:35:50.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1m[Train] Loss: 0.2288 | Accuracy: 0.9330 | Precision: 0.9333 | Recall: 0.9325 | F1 Score: 0.9327\u001b[0m\n",
      "\u001b[32m2024-10-11 13:35:50.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1m[Val  ] Loss: 0.0821 | Accuracy: 0.9753 | Precision: 0.9753 | Recall: 0.9754 | F1 Score: 0.9752\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:55<01:23, 27.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-11 13:36:18.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mEpoch [2/5]\u001b[0m\n",
      "\u001b[32m2024-10-11 13:36:18.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1m[Train] Loss: 0.0613 | Accuracy: 0.9815 | Precision: 0.9814 | Recall: 0.9813 | F1 Score: 0.9814\u001b[0m\n",
      "\u001b[32m2024-10-11 13:36:18.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1m[Val  ] Loss: 0.0523 | Accuracy: 0.9843 | Precision: 0.9841 | Recall: 0.9842 | F1 Score: 0.9841\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [01:24<00:56, 28.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-11 13:36:46.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mEpoch [3/5]\u001b[0m\n",
      "\u001b[32m2024-10-11 13:36:46.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1m[Train] Loss: 0.0423 | Accuracy: 0.9865 | Precision: 0.9865 | Recall: 0.9864 | F1 Score: 0.9864\u001b[0m\n",
      "\u001b[32m2024-10-11 13:36:46.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1m[Val  ] Loss: 0.0542 | Accuracy: 0.9840 | Precision: 0.9840 | Recall: 0.9838 | F1 Score: 0.9839\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [01:58<00:30, 30.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-11 13:37:21.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mEpoch [4/5]\u001b[0m\n",
      "\u001b[32m2024-10-11 13:37:21.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1m[Train] Loss: 0.0322 | Accuracy: 0.9899 | Precision: 0.9898 | Recall: 0.9898 | F1 Score: 0.9898\u001b[0m\n",
      "\u001b[32m2024-10-11 13:37:21.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1m[Val  ] Loss: 0.0498 | Accuracy: 0.9867 | Precision: 0.9865 | Recall: 0.9866 | F1 Score: 0.9865\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:30<00:00, 30.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-11 13:37:53.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mEpoch [5/5]\u001b[0m\n",
      "\u001b[32m2024-10-11 13:37:53.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1m[Train] Loss: 0.0248 | Accuracy: 0.9920 | Precision: 0.9919 | Recall: 0.9919 | F1 Score: 0.9919\u001b[0m\n",
      "\u001b[32m2024-10-11 13:37:53.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1m[Val  ] Loss: 0.0482 | Accuracy: 0.9855 | Precision: 0.9856 | Recall: 0.9852 | F1 Score: 0.9854\u001b[0m\n",
      "\u001b[32m2024-10-11 13:37:53.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmdsist.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mTraining completed.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/11 13:37:53 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2024/10/11 13:38:04 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.19.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torchvision==0.19.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2024/10/11 13:38:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/11 13:38:08 INFO mlflow.tracking._tracking_service.client: View run Train at: https://dagshub.com/Zhengyong8119/MLOps-mdsist.mlflow/#/experiments/14/runs/ef51e37f6fd14b87ab58964e1153bd5d.\n",
      "2024/10/11 13:38:08 INFO mlflow.tracking._tracking_service.client: View experiment at: https://dagshub.com/Zhengyong8119/MLOps-mdsist.mlflow/#/experiments/14.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI'))\n",
    "mlflow.set_experiment(EXPERIMENT_ID)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag('mlflow.runName', 'Train')\n",
    "\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_param('epochs', EPOCHS)\n",
    "    mlflow.log_param('batch_size', BATCH_SIZE)\n",
    "    mlflow.log_param('learning_rate', LEARNING_RATE)\n",
    "    mlflow.log_param('seed', SEED)\n",
    "\n",
    "    # Start emissions tracking\n",
    "    #emissions_tracker = cc.EmissionsTracker(project_name='MDSIST', experiment_id=EXPERIMENT_ID  )\n",
    "    #emissions_tracker.start()\n",
    "    \n",
    "    # Train\n",
    "    trainer = Trainer(model, optimizer, device)\n",
    "    trainer.train(train_loader, val_loader, 5)\n",
    "\n",
    "    # Stop emissions tracking and log them\n",
    "    #emissions = emissions_tracker.stop()\n",
    "    #mlflow.log_metric('emissions_kg_co2', emissions)\n",
    "\n",
    "    # Log the model itself to MLflow\n",
    "    mlflow.pytorch.log_model(trainer.model, 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer.model, './model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdsist-j1bbbV5p-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
